{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2 Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# Detectron2 Beginner's Tutorial\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n",
        "* Run inference on images or videos, with an existing detectron2 model\n",
        "* Train a detectron2 model on a new dataset\n",
        "\n",
        "You can make a copy of this tutorial by \"File -> Open in playground mode\" and make changes there. __DO NOT__ request access to this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JxxLubvU4VA",
        "outputId": "249fa768-b513-47b3-b60f-240755c078ef"
      },
      "source": [
        "!nvidia-smi\n",
        "!nvcc -V"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZfXeCpjihzc"
      },
      "source": [
        "### Update and purge Nvidia Driver\n",
        "#### https://medium.com/analytics-vidhya/install-cuda-11-2-cudnn-8-1-0-and-python-3-9-on-rtx3090-for-deep-learning-fcf96c95f7a1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH78B0LUU9cl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29e19de3-78a6-4cb6-cb0a-7de1c55d03fe"
      },
      "source": [
        "!python -c \"import torch; print(torch.__version__); import torchvision; print(torchvision.__version__)\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu111\n",
            "0.9.1+cu111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37b6ccfa-fa1b-495a-d771-c16458ec41eb"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "!pip install cmake\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyyaml==5.1 in /usr/local/lib/python3.7/dist-packages (5.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.7/dist-packages (3.12.0)\n",
            "1.8.1+cu111 False\n",
            "gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Copyright (C) 2017 Free Software Foundation, Inc.\n",
            "This is free software; see the source for copying conditions.  There is NO\n",
            "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNn9jbBgRR0C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44258a9-c48a-4cba-be9f-8ef50e462761"
      },
      "source": [
        "# Manually install torch 1.8.1 as bug in 1.8.0\n",
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!pip install torchtext==0.9.1\n",
        "\n",
        "#exit(0) # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.8.1+cu111 in /usr/local/lib/python3.7/dist-packages (1.8.1+cu111)\n",
            "Requirement already satisfied: torchvision==0.9.1+cu111 in /usr/local/lib/python3.7/dist-packages (0.9.1+cu111)\n",
            "Requirement already satisfied: torchaudio==0.8.1 in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "Requirement already satisfied: torchtext==0.9.1 in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (1.19.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (4.41.1)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (1.8.1+cu111)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchtext==0.9.1) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzoPUAH9iRxX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebfed308-b870-4b63-8944-1846c1c04a74"
      },
      "source": [
        "print(torch.__version__, torch.cuda.is_available())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu111 False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11223755-d70b-4103-8ef5-69d318339f59"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.8)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8.\")   # need to manually install torch 1.8 if Colab changes its default version\n",
        "!python -m pip install detectron2==0.4 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "#exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
            "Collecting detectron2==0.4\n",
            "\u001b[?25l  Downloading https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/detectron2-0.4%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.2MB)\n",
            "\u001b[K     |████████████████████████████████| 6.2MB 516kB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (3.2.2)\n",
            "Collecting fvcore<0.1.4,>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6b/68/2bacb80e13c4084dfc37fec8f17706a1de4c248157561ff33e463399c4f5/fvcore-0.1.3.post20210317.tar.gz (47kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.4MB/s \n",
            "\u001b[?25hCollecting iopath>=0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/af/20/65dd9bd25a1eb7fa35b5ae38d289126af065f8a0c1f6a90564f4bff0f89d/iopath-0.1.9-py3-none-any.whl\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (2.5.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (4.41.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (1.3.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (1.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (1.1.0)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (2.0.2)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (0.8.9)\n",
            "Collecting omegaconf>=2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/96/1966b48bfe6ca64bfadfa7bcc9a8d73c5d83b4be769321fcc5d617abeb0c/omegaconf-2.1.0-py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.4) (0.16.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.4) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.4,>=0.1.3->detectron2==0.4) (5.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (57.0.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.34.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (1.31.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (0.36.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (0.4.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.4) (3.12.4)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->detectron2==0.4) (0.29.23)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 43.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->detectron2==0.4) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.4) (4.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.4) (1.24.3)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.4) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->detectron2==0.4) (3.4.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard->detectron2==0.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.4) (3.1.1)\n",
            "Building wheels for collected packages: fvcore, antlr4-python3-runtime\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.3.post20210317-cp37-none-any.whl size=58543 sha256=a3da656e642d8222ea2bd1b3deed822f55153e64661d306476216e515fbfae0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/ee/3a/5c531df777c03d8c67f22c65f97d6f75321087482d05a9b218\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=43c8ed3b803be70a30e10e98a9f8bc8967150a1dfce6c60d4692aba237cd14dc\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n",
            "Successfully built fvcore antlr4-python3-runtime\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore, antlr4-python3-runtime, omegaconf, detectron2\n",
            "Successfully installed antlr4-python3-runtime-4.8 detectron2-0.4+cu101 fvcore-0.1.3.post20210317 iopath-0.1.9 omegaconf-2.1.0 portalocker-2.3.0 yacs-0.1.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeJp986zrkVS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5bfb9bb-5e09-4ff5-cfe5-83542cc108e3"
      },
      "source": [
        "!python -c 'import torch;print(torch.eye(3))'\n",
        "!python -c 'from torch.utils.collect_env import main; main()'"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "Collecting environment information...\n",
            "PyTorch version: 1.8.1+cu111\n",
            "Is debug build: False\n",
            "CUDA used to build PyTorch: 11.1\n",
            "ROCM used to build PyTorch: N/A\n",
            "\n",
            "OS: Ubuntu 18.04.5 LTS (x86_64)\n",
            "GCC version: (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\n",
            "Clang version: 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\n",
            "CMake version: version 3.12.0\n",
            "\n",
            "Python version: 3.7 (64-bit runtime)\n",
            "Is CUDA available: False\n",
            "CUDA runtime version: No CUDA\n",
            "GPU models and configuration: No CUDA\n",
            "Nvidia driver version: No CUDA\n",
            "cuDNN version: No CUDA\n",
            "HIP runtime version: N/A\n",
            "MIOpen runtime version: N/A\n",
            "\n",
            "Versions of relevant libraries:\n",
            "[pip3] numpy==1.19.5\n",
            "[pip3] torch==1.8.1+cu111\n",
            "[pip3] torchaudio==0.8.1\n",
            "[pip3] torchsummary==1.5.1\n",
            "[pip3] torchtext==0.9.1\n",
            "[pip3] torchvision==0.9.1+cu111\n",
            "[conda] Could not collect\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQbadqxLncgj"
      },
      "source": [
        "## FineTuning PubLayNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrm0xaEDnat9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e368521-0924-4776-f6ab-2415241ba965"
      },
      "source": [
        "# download, decompress the data\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1NAgGrYoQJwdNXE-nFzx0yEJEoqxMcqh2' -O siemens.zip # exchange\n",
        "!unzip siemens.zip -d datasets\n",
        "!rm -r siemens.zip\n",
        "!ls 'datasets/siemens'"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-25 10:08:32--  https://docs.google.com/uc?export=download&id=1NAgGrYoQJwdNXE-nFzx0yEJEoqxMcqh2\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.13.78, 2607:f8b0:4004:829::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.13.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-04-9c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ruti4s3m00snb0vj9s46amd1gs2fm711/1624615650000/11785652857695517745/*/1NAgGrYoQJwdNXE-nFzx0yEJEoqxMcqh2?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-06-25 10:08:33--  https://doc-04-9c-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/ruti4s3m00snb0vj9s46amd1gs2fm711/1624615650000/11785652857695517745/*/1NAgGrYoQJwdNXE-nFzx0yEJEoqxMcqh2?e=download\n",
            "Resolving doc-04-9c-docs.googleusercontent.com (doc-04-9c-docs.googleusercontent.com)... 142.251.33.193, 2607:f8b0:4004:837::2001\n",
            "Connecting to doc-04-9c-docs.googleusercontent.com (doc-04-9c-docs.googleusercontent.com)|142.251.33.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-zip-compressed]\n",
            "Saving to: ‘siemens.zip’\n",
            "\n",
            "siemens.zip             [ <=>                ]  16.76M   107MB/s    in 0.2s    \n",
            "\n",
            "2021-06-25 10:08:33 (107 MB/s) - ‘siemens.zip’ saved [17574935]\n",
            "\n",
            "Archive:  siemens.zip\n",
            "replace datasets/siemens/annotations/1.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: datasets/siemens/annotations/1.json  \n",
            "  inflating: datasets/siemens/annotations/10.json  \n",
            "  inflating: datasets/siemens/annotations/11.json  \n",
            "  inflating: datasets/siemens/labelme2coco.py  \n",
            "  inflating: datasets/siemens/README.md  \n",
            "  inflating: datasets/siemens/train/1.json  \n",
            "  inflating: datasets/siemens/train/1.PNG  \n",
            "  inflating: datasets/siemens/train/10.json  \n",
            "  inflating: datasets/siemens/train/10.PNG  \n",
            "  inflating: datasets/siemens/train/12.json  \n",
            "  inflating: datasets/siemens/train/12.PNG  \n",
            "  inflating: datasets/siemens/train/13.json  \n",
            "  inflating: datasets/siemens/train/13.PNG  \n",
            "  inflating: datasets/siemens/train/15.json  \n",
            "  inflating: datasets/siemens/train/15.PNG  \n",
            "  inflating: datasets/siemens/train/16.json  \n",
            "  inflating: datasets/siemens/train/16.PNG  \n",
            "  inflating: datasets/siemens/train/2.json  \n",
            "  inflating: datasets/siemens/train/2.PNG  \n",
            "  inflating: datasets/siemens/train/3.PNG  \n",
            "  inflating: datasets/siemens/train/5.json  \n",
            "  inflating: datasets/siemens/train/5.PNG  \n",
            "  inflating: datasets/siemens/train/6.json  \n",
            "  inflating: datasets/siemens/train/6.PNG  \n",
            "  inflating: datasets/siemens/train/7.json  \n",
            "  inflating: datasets/siemens/train/7.PNG  \n",
            "  inflating: datasets/siemens/train/8.json  \n",
            "  inflating: datasets/siemens/train/8.PNG  \n",
            "  inflating: datasets/siemens/train/images/1.json  \n",
            "  inflating: datasets/siemens/train/images/1.PNG  \n",
            "  inflating: datasets/siemens/train/images/10.json  \n",
            "  inflating: datasets/siemens/train/images/10.PNG  \n",
            "  inflating: datasets/siemens/train/images/11.PNG  \n",
            "  inflating: datasets/siemens/train/images/12.json  \n",
            "  inflating: datasets/siemens/train/images/12.PNG  \n",
            "  inflating: datasets/siemens/train/images/13.json  \n",
            "  inflating: datasets/siemens/train/images/13.PNG  \n",
            "  inflating: datasets/siemens/train/images/14.PNG  \n",
            "  inflating: datasets/siemens/train/images/15.json  \n",
            "  inflating: datasets/siemens/train/images/15.PNG  \n",
            "  inflating: datasets/siemens/train/images/16.json  \n",
            "  inflating: datasets/siemens/train/images/16.PNG  \n",
            "  inflating: datasets/siemens/train/images/2.PNG  \n",
            "  inflating: datasets/siemens/train/images/3.PNG  \n",
            "  inflating: datasets/siemens/train/images/4.PNG  \n",
            "  inflating: datasets/siemens/train/images/5.PNG  \n",
            "  inflating: datasets/siemens/train/images/6.PNG  \n",
            "  inflating: datasets/siemens/train/images/7.PNG  \n",
            "  inflating: datasets/siemens/train/images/8.PNG  \n",
            "  inflating: datasets/siemens/train/images/9.PNG  \n",
            "  inflating: datasets/siemens/train/images/d1-0val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-0val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-10val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-10val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-11val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-11val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-12val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-12val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-13val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-13val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-14val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-14val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-15val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-15val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-1val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-1val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-2val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-2val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-3val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-3val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-4val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-4val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-5val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-5val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-6val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-6val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-7val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-7val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-8val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-8val.png  \n",
            "  inflating: datasets/siemens/train/images/d1-9val.jpg  \n",
            "  inflating: datasets/siemens/train/images/d1-9val.png  \n",
            "  inflating: datasets/siemens/train/train2021.json  \n",
            "  inflating: datasets/siemens/val/11.json  \n",
            "  inflating: datasets/siemens/val/11.PNG  \n",
            "  inflating: datasets/siemens/val/14.json  \n",
            "  inflating: datasets/siemens/val/14.PNG  \n",
            "  inflating: datasets/siemens/val/4.json  \n",
            "  inflating: datasets/siemens/val/4.PNG  \n",
            "  inflating: datasets/siemens/val/images/1.PNG  \n",
            "  inflating: datasets/siemens/val/images/10.PNG  \n",
            "  inflating: datasets/siemens/val/images/11.json  \n",
            "  inflating: datasets/siemens/val/images/11.PNG  \n",
            "  inflating: datasets/siemens/val/images/12.PNG  \n",
            "  inflating: datasets/siemens/val/images/13.PNG  \n",
            "  inflating: datasets/siemens/val/images/14.json  \n",
            "  inflating: datasets/siemens/val/images/14.PNG  \n",
            "  inflating: datasets/siemens/val/images/15.PNG  \n",
            "  inflating: datasets/siemens/val/images/16.PNG  \n",
            "  inflating: datasets/siemens/val/images/2.PNG  \n",
            "  inflating: datasets/siemens/val/images/3.PNG  \n",
            "  inflating: datasets/siemens/val/images/4.PNG  \n",
            "  inflating: datasets/siemens/val/images/5.PNG  \n",
            "  inflating: datasets/siemens/val/images/6.PNG  \n",
            "  inflating: datasets/siemens/val/images/7.PNG  \n",
            "  inflating: datasets/siemens/val/images/8.PNG  \n",
            "  inflating: datasets/siemens/val/images/9.PNG  \n",
            "  inflating: datasets/siemens/val/val2021.json  \n",
            "ls: cannot access 'Siemens': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlyxbGLmoDTD"
      },
      "source": [
        "### Register Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhnaAo5HoCgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bcfd937-6967-4de0-c936-d7aa4625af99"
      },
      "source": [
        "from detectron2.data.datasets import load_coco_json, register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "cur_dir = os.getcwd()\n",
        "data_dir = os.path.join(cur_dir, \"datasets/siemens\")\n",
        "\n",
        "# Training dataset\n",
        "training_dataset_name = \"dla_train\"\n",
        "training_json_file = os.path.join(data_dir, \"train/train2021.json\")\n",
        "training_img_dir = os.path.join(data_dir, \"train/images\")\n",
        "\n",
        "# Register custom training dataset\n",
        "register_coco_instances(training_dataset_name, {}, training_json_file, training_img_dir)\n",
        "\n",
        "# Validation dataset\n",
        "validation_dataset_name = \"dla_val\"\n",
        "validation_json_file = os.path.join(data_dir, \"val/val2021.json\")\n",
        "validation_img_dir = os.path.join(data_dir, \"val/images\")\n",
        "    \n",
        "# Register custom training dataset\n",
        "register_coco_instances(validation_dataset_name, {}, validation_json_file, validation_img_dir)\n",
        "    \n",
        "# Get training/validation dictionary\n",
        "training_dict = load_coco_json(training_json_file, training_img_dir, dataset_name=training_dataset_name)\n",
        "validation_dict = load_coco_json(validation_json_file, validation_img_dir, dataset_name=validation_dataset_name)\n",
        "\n",
        "# Register metadata\n",
        "training_metadata = MetadataCatalog.get(training_dataset_name)\n",
        "validation_metadata = MetadataCatalog.get(validation_dataset_name)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/25 10:07:48 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[06/25 10:07:48 d2.data.datasets.coco]: \u001b[0mLoaded 6 images in COCO format from /content/datasets/siemens/train/train2021.json\n",
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/25 10:07:48 d2.data.datasets.coco]: \u001b[0m\n",
            "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
            "\n",
            "\u001b[32m[06/25 10:07:48 d2.data.datasets.coco]: \u001b[0mLoaded 2 images in COCO format from /content/datasets/siemens/val/val2021.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZeLzshI40Le",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217ea027-7f87-430f-b2c0-7b65391e6c83"
      },
      "source": [
        "!git clone https://github.com/JaninaMattes/detectron2.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'detectron2'...\n",
            "remote: Enumerating objects: 2687, done.\u001b[K\n",
            "remote: Counting objects: 100% (185/185), done.\u001b[K\n",
            "remote: Compressing objects: 100% (155/155), done.\u001b[K\n",
            "remote: Total 2687 (delta 54), reused 98 (delta 29), pack-reused 2502\u001b[K\n",
            "Receiving objects: 100% (2687/2687), 37.82 MiB | 9.56 MiB/s, done.\n",
            "Resolving deltas: 100% (1691/1691), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63aQoDVrK4o"
      },
      "source": [
        "### Get pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D1SkayvrNmM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22de4eed-46ce-4e9b-f26f-1038727ab003"
      },
      "source": [
        "# download pre-trained model\n",
        "!wget https://www.dropbox.com/sh/wgt9skz67usliei/AADGw0h1y7K5vO0akulyXm-qa/model_final.pth\n",
        "!ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-25 10:07:58--  https://www.dropbox.com/sh/wgt9skz67usliei/AADGw0h1y7K5vO0akulyXm-qa/model_final.pth\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:601c:18::a27d:612\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /sh/raw/wgt9skz67usliei/AADGw0h1y7K5vO0akulyXm-qa/model_final.pth [following]\n",
            "--2021-06-25 10:07:58--  https://www.dropbox.com/sh/raw/wgt9skz67usliei/AADGw0h1y7K5vO0akulyXm-qa/model_final.pth\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com/cd/0/inline/BRFGSlXzXe_zdIE25Z47qz7xRUOV_JeSpW4DyrrFNY_7j7qNBdR0ez3SbdZoCeqOPVq9LNoMUh-kUZGg5RQI0gXB2UffaLgeB59VazdUpzVqBppWwYEWXBh-aPIhzomZQYb5lU10Ux8qhH9gZdcxWT4I/file# [following]\n",
            "--2021-06-25 10:07:58--  https://ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com/cd/0/inline/BRFGSlXzXe_zdIE25Z47qz7xRUOV_JeSpW4DyrrFNY_7j7qNBdR0ez3SbdZoCeqOPVq9LNoMUh-kUZGg5RQI0gXB2UffaLgeB59VazdUpzVqBppWwYEWXBh-aPIhzomZQYb5lU10Ux8qhH9gZdcxWT4I/file\n",
            "Resolving ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com (ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com)... 162.125.6.15, 2620:100:601c:15::a27d:60f\n",
            "Connecting to ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com (ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com)|162.125.6.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BRFqjrCFuReVK3w3UozV8wnDqQuic-uTfWusA2AW-LQ4k1EcSgtL_urlArAcsoS47JS0w8141j1ktep3NetU5_kyb2B2zKcPZdhktBsajLHhQntQKnm9Ra_NEFNjRyYamKIqkXk5LDV11_EyWJMoZHwQCyeW_JGGXsga0avFPieUDyfHHdKmPXLWVeFtzcbsvuWhLxYlWR1KxLb7ecyisJx7RhxQC0f1WFCTPyacj45QXHbjaAShieYi-SZbHyGgqPDoI8jM2eu9ly_IR9leLZ14HtFix_7EL603UXmmjNQw5mb9s6aPKZvocnuwK7dKnddPc2XQEEZZ7ly7pfa7RG6SZVt-RGyzkSQUV1LSM1F444ssjiihWhauTdtNRTpJHoQ/file [following]\n",
            "--2021-06-25 10:07:59--  https://ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com/cd/0/inline2/BRFqjrCFuReVK3w3UozV8wnDqQuic-uTfWusA2AW-LQ4k1EcSgtL_urlArAcsoS47JS0w8141j1ktep3NetU5_kyb2B2zKcPZdhktBsajLHhQntQKnm9Ra_NEFNjRyYamKIqkXk5LDV11_EyWJMoZHwQCyeW_JGGXsga0avFPieUDyfHHdKmPXLWVeFtzcbsvuWhLxYlWR1KxLb7ecyisJx7RhxQC0f1WFCTPyacj45QXHbjaAShieYi-SZbHyGgqPDoI8jM2eu9ly_IR9leLZ14HtFix_7EL603UXmmjNQw5mb9s6aPKZvocnuwK7dKnddPc2XQEEZZ7ly7pfa7RG6SZVt-RGyzkSQUV1LSM1F444ssjiihWhauTdtNRTpJHoQ/file\n",
            "Reusing existing connection to ucc7aa72c9744e585564d7c6847f.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 503147199 (480M) [application/octet-stream]\n",
            "Saving to: ‘model_final.pth.1’\n",
            "\n",
            "model_final.pth.1   100%[===================>] 479.84M   122MB/s    in 3.8s    \n",
            "\n",
            "2021-06-25 10:08:03 (126 MB/s) - ‘model_final.pth.1’ saved [503147199/503147199]\n",
            "\n",
            "datasets    model_final.pth    sample_data\n",
            "detectron2  model_final.pth.1  siemens.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PakqhRNorz-b"
      },
      "source": [
        "### Train the pre-trained Mask-RCNN R50 FPN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "1DpuqgInmyNR",
        "outputId": "9f51bf75-9ab6-4192-8f5b-fb998a00e8a9"
      },
      "source": [
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultTrainer, default_argument_parser, default_setup, hooks, launch\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(\"detectron2/configs/DLA_mask_rcnn_R_101_FPN_3x.yaml\")\n",
        "cfg.DATASETS.TRAIN = (\"dla_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\")\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "cfg.SOLVER.BASE_LR = 0.00025\n",
        "cfg.SOLVER.MAX_ITER = 1000\n",
        "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4\n",
        "\n",
        "# Create output\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Serialize the training config\n",
        "cfg_str = cfg.dump()\n",
        "with open(os.path.join(cfg.OUTPUT_DIR, \"train_config.yaml\"), \"w\") as f:\n",
        "    f.write(cfg_str)\n",
        "f.close()\n",
        "\n",
        "# Start training with Default Trainer\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[06/25 10:10:21 d2.config.compat]: \u001b[0mConfig 'detectron2/configs/DLA_mask_rcnn_R_101_FPN_3x.yaml' has no VERSION. Assuming it to be compatible with latest v2.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-b3f3b02145b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Start training with Default Trainer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDefaultTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_or_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;31m# Assume these objects must be constructed in this order.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m         \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0mdata_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_train_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/engine/defaults.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(cls, cfg)\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0mOverwrite\u001b[0m \u001b[0mit\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0myou\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0md\u001b[0m \u001b[0mlike\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \"\"\"\n\u001b[0;32m--> 452\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m         \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model:\\n{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/detectron2/modeling/meta_arch/build.py\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mmeta_arch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMETA_ARCHITECTURE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMETA_ARCH_REGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_arch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Rr7gqlwdMi"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxsCvb59wcVa"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kw3MFmqwrkk"
      },
      "source": [
        "### Evaluation of model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bBaXpnSwq97"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzktdKGqw_Jx"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_balloon_dicts(\"siemens_dataset/val\")\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=balloon_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YSIMIIHxEgM"
      },
      "source": [
        "### Check metrics for COCO API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCn_NwLsxEAc"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"dla_val\", (\"bbox\", \"segm\"), False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"dla_val\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-yhFoxvurco"
      },
      "source": [
        "### Download fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HunigT5tuqty"
      },
      "source": [
        "files.download('fine_tunes_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}