{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detectron2 Tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHnVupBBn9eR"
      },
      "source": [
        "# Detectron2 Beginner's Tutorial\n",
        "\n",
        "<img src=\"https://dl.fbaipublicfiles.com/detectron2/Detectron2-Logo-Horz.png\" width=\"500\">\n",
        "\n",
        "Welcome to detectron2! This is the official colab tutorial of detectron2. Here, we will go through some basics usage of detectron2, including the following:\n",
        "* Run inference on images or videos, with an existing detectron2 model\n",
        "* Train a detectron2 model on a new dataset\n",
        "\n",
        "You can make a copy of this tutorial by \"File -> Open in playground mode\" and make changes there. __DO NOT__ request access to this tutorial.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vM54r6jlKTII"
      },
      "source": [
        "# Install detectron2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JxxLubvU4VA",
        "outputId": "f408f0d1-6879-41ac-bc94-dba499a858d9"
      },
      "source": [
        "!nvidia-smi\n",
        "!nvcc -V"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Jun 25 07:36:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "Cuda compilation tools, release 11.0, V11.0.221\n",
            "Build cuda_11.0_bu.TC445_37.28845127_0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZfXeCpjihzc"
      },
      "source": [
        "### Update and purge Nvidia Driver\n",
        "#### https://medium.com/analytics-vidhya/install-cuda-11-2-cudnn-8-1-0-and-python-3-9-on-rtx3090-for-deep-learning-fcf96c95f7a1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH78B0LUU9cl"
      },
      "source": [
        "!python -c \"import torch; print(torch.__version__); import torchvision; print(torchvision.__version__)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_FzH13EjseR"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1\n",
        "!pip install cmake\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNn9jbBgRR0C",
        "outputId": "4f86ba31-1d92-49a4-8903-0ca5e0f5faf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Manually install torch 1.8.1 as bug in 1.8.0\n",
        "!pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 torchaudio==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "#!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
        "!pip install torchtext==0.9.1\n",
        "\n",
        "#exit(0) # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.8.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torch-1.8.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (1982.2MB)\n",
            "\u001b[K     |█████████████▌                  | 834.1MB 1.4MB/s eta 0:14:01tcmalloc: large alloc 1147494400 bytes == 0x55b3dac14000 @  0x7f8a0f4e4615 0x55b3a1825cdc 0x55b3a190552a 0x55b3a1828afd 0x55b3a1919fed 0x55b3a189c988 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189c7f0 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a199d3e1 0x55b3a18fd6a9 0x55b3a1868cc4 0x55b3a1829559 0x55b3a189d4f8 0x55b3a182a30a 0x55b3a18983b5 0x55b3a18977ad 0x55b3a182a3ea 0x55b3a18983b5 0x55b3a182a30a 0x55b3a18983b5\n",
            "\u001b[K     |█████████████████               | 1055.7MB 1.4MB/s eta 0:11:20tcmalloc: large alloc 1434370048 bytes == 0x55b41f26a000 @  0x7f8a0f4e4615 0x55b3a1825cdc 0x55b3a190552a 0x55b3a1828afd 0x55b3a1919fed 0x55b3a189c988 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189c7f0 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a199d3e1 0x55b3a18fd6a9 0x55b3a1868cc4 0x55b3a1829559 0x55b3a189d4f8 0x55b3a182a30a 0x55b3a18983b5 0x55b3a18977ad 0x55b3a182a3ea 0x55b3a18983b5 0x55b3a182a30a 0x55b3a18983b5\n",
            "\u001b[K     |█████████████████████▋          | 1336.2MB 1.2MB/s eta 0:08:56tcmalloc: large alloc 1792966656 bytes == 0x55b3a409c000 @  0x7f8a0f4e4615 0x55b3a1825cdc 0x55b3a190552a 0x55b3a1828afd 0x55b3a1919fed 0x55b3a189c988 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189c7f0 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a199d3e1 0x55b3a18fd6a9 0x55b3a1868cc4 0x55b3a1829559 0x55b3a189d4f8 0x55b3a182a30a 0x55b3a18983b5 0x55b3a18977ad 0x55b3a182a3ea 0x55b3a18983b5 0x55b3a182a30a 0x55b3a18983b5\n",
            "\u001b[K     |███████████████████████████▎    | 1691.1MB 1.4MB/s eta 0:03:29tcmalloc: large alloc 2241208320 bytes == 0x55b40ee84000 @  0x7f8a0f4e4615 0x55b3a1825cdc 0x55b3a190552a 0x55b3a1828afd 0x55b3a1919fed 0x55b3a189c988 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189c7f0 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a1898853 0x55b3a191ae36 0x55b3a199d3e1 0x55b3a18fd6a9 0x55b3a1868cc4 0x55b3a1829559 0x55b3a189d4f8 0x55b3a182a30a 0x55b3a18983b5 0x55b3a18977ad 0x55b3a182a3ea 0x55b3a18983b5 0x55b3a182a30a 0x55b3a18983b5\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 1.3MB/s eta 0:00:01tcmalloc: large alloc 1982177280 bytes == 0x55b4947e6000 @  0x7f8a0f4e31e7 0x55b3a185bf37 0x55b3a1825cdc 0x55b3a190552a 0x55b3a1828afd 0x55b3a1919fed 0x55b3a189c988 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a182a30a 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a18974ae\n",
            "tcmalloc: large alloc 2477727744 bytes == 0x55b57eefe000 @  0x7f8a0f4e4615 0x55b3a1825cdc 0x55b3a190552a 0x55b3a1828afd 0x55b3a1919fed 0x55b3a189c988 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189860e 0x55b3a182a30a 0x55b3a189860e 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a18974ae 0x55b3a182a3ea 0x55b3a189932a 0x55b3a18974ae 0x55b3a182aa81\n",
            "\u001b[K     |████████████████████████████████| 1982.2MB 3.9kB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1+cu111\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu111/torchvision-0.9.1%2Bcu111-cp37-cp37m-linux_x86_64.whl (17.6MB)\n",
            "\u001b[K     |████████████████████████████████| 17.6MB 191kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1+cu111) (1.19.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.1+cu111) (7.1.2)\n",
            "\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.1+cu111 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch, torchvision, torchaudio\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzoPUAH9iRxX"
      },
      "source": [
        "print(torch.__version__, torch.cuda.is_available())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4hmGYk1dL"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.8)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "import torch\n",
        "assert torch.__version__.startswith(\"1.8.\")   # need to manually install torch 1.8 if Colab changes its default version\n",
        "!python -m pip install detectron2==0.4 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
        "#exit(0)  # After installation, you need to \"restart runtime\" in Colab. This line can also restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeJp986zrkVS"
      },
      "source": [
        "!python -c 'import torch;print(torch.eye(3))'\n",
        "!python -c 'from torch.utils.collect_env import main; main()'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyAvNCJMmvFF"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQbadqxLncgj"
      },
      "source": [
        "## FineTuning PubLayNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wrm0xaEDnat9"
      },
      "source": [
        "# download, decompress the data\n",
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1NAgGrYoQJwdNXE-nFzx0yEJEoqxMcqh2' -O siemens.zip # exchange\n",
        "!unzip siemens.zip -d datasets\n",
        "!ls 'Siemens'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlyxbGLmoDTD"
      },
      "source": [
        "### Register Custom Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhnaAo5HoCgg"
      },
      "source": [
        "from detectron2.data.datasets import load_coco_json, register_coco_instances\n",
        "from detectron2.data import MetadataCatalog\n",
        "\n",
        "cur_dir = os.getcwd()\n",
        "data_dir = os.path.join(cur_dir, \"datasets/siemens\")\n",
        "\n",
        "# Training dataset\n",
        "training_dataset_name = \"dla_train\"\n",
        "training_json_file = os.path.join(data_dir, \"train/train2021.json\")\n",
        "training_img_dir = os.path.join(data_dir, \"train/images\")\n",
        "\n",
        "# Register custom training dataset\n",
        "register_coco_instances(training_dataset_name, {}, training_json_file, training_img_dir)\n",
        "\n",
        "# Validation dataset\n",
        "validation_dataset_name = \"dla_val\"\n",
        "validation_json_file = os.path.join(data_dir, \"val/val2021.json\")\n",
        "validation_img_dir = os.path.join(data_dir, \"val/images\")\n",
        "    \n",
        "# Register custom training dataset\n",
        "register_coco_instances(validation_dataset_name, {}, validation_json_file, validation_img_dir)\n",
        "    \n",
        "# Get training/validation dictionary\n",
        "training_dict = load_coco_json(training_json_file, training_img_dir, dataset_name=training_dataset_name)\n",
        "validation_dict = load_coco_json(validation_json_file, validation_img_dir, dataset_name=validation_dataset_name)\n",
        "\n",
        "# Register metadata\n",
        "training_metadata = MetadataCatalog.get(training_dataset_name)\n",
        "validation_metadata = MetadataCatalog.get(validation_dataset_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZeLzshI40Le"
      },
      "source": [
        "!git clone https://github.com/JaninaMattes/detectron2.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63aQoDVrK4o"
      },
      "source": [
        "### Get pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D1SkayvrNmM"
      },
      "source": [
        "# download pre-trained model\n",
        "!mkdir -p detectron2/pretrained_models/Resnet-101/\n",
        "!wget https://www.dropbox.com/sh/wgt9skz67usliei/AADGw0h1y7K5vO0akulyXm-qa/model_final.pth?dl=0 -P /dev/null/detectron2/pretrained_models/Resnet-101/\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PakqhRNorz-b"
      },
      "source": [
        "### Train the pre-trained Mask-RCNN R50 FPN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USiRrEOory0r"
      },
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "\n",
        "def setup(config_file, training_metadata):\n",
        "    \"\"\"\n",
        "    Create configs and perform basic setups.\n",
        "    \"\"\"\n",
        "    cfg = get_cfg()\n",
        "    cfg.merge_from_file(config_file)\n",
        "    cfg.DATASETS.TRAIN = (\"dla_train\",)\n",
        "    cfg.DATASETS.TEST = (\"val_train\")\n",
        "    cfg.DATALOADER.NUM_WORKERS = 2\n",
        "    cfg.MODEL.WEIGHTS = \"pretrained_models/Resnet-101/model_final.pth\"\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 2\n",
        "    cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
        "    cfg.SOLVER.MAX_ITER = 300    # 300 iterations seems good enough for a toy dataset; you will need to train longer for a practical dataset\n",
        "    cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
        "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # 128 faster, and good enough for a toy dataset (default: 512)\n",
        "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = len(training_metadata.thing_classes)  # has 5 classes (see https://detectron2.readthedocs.io/tutorials/datasets.html#update-the-config-for-new-datasets)\n",
        "    \n",
        "    # Solver options\n",
        "    cfg.SOLVER.BASE_LR = 1e-3           # Base learning rate\n",
        "    cfg.SOLVER.GAMMA = 0.5              # Learning rate decay\n",
        "    cfg.SOLVER.STEPS = (250, 500, 750)  # Iterations at which to decay learning rate\n",
        "    cfg.SOLVER.MAX_ITER = 1000          # Maximum number of iterations\n",
        "    cfg.SOLVER.WARMUP_ITERS = 100       # Warmup iterations to linearly ramp learning rate from zero\n",
        "    cfg.SOLVER.IMS_PER_BATCH = 1        # Lower to reduce memory usage (1 is the lowest)\n",
        "    return cfg\n",
        "\n",
        "cfg = setup(config_file=\"detectron2/configs/DLA_mask_rcnn_R_101_FPN_3x.yaml\", training_metadata=training_metadata)\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Start training\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5Rr7gqlwdMi"
      },
      "source": [
        "### Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxsCvb59wcVa"
      },
      "source": [
        "# Look at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kw3MFmqwrkk"
      },
      "source": [
        "### Evaluation of model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bBaXpnSwq97"
      },
      "source": [
        "# Inference should use the config with parameters that are used in training\n",
        "# cfg now already contains everything we've set previously. We changed it a little bit for inference:\n",
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set a custom testing threshold\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzktdKGqw_Jx"
      },
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_balloon_dicts(\"siemens_dataset/val\")\n",
        "for d in random.sample(dataset_dicts, 3):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)  # format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=balloon_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YSIMIIHxEgM"
      },
      "source": [
        "### Check metrics for COCO API "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCn_NwLsxEAc"
      },
      "source": [
        "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
        "from detectron2.data import build_detection_test_loader\n",
        "evaluator = COCOEvaluator(\"dla_val\", (\"bbox\", \"segm\"), False, output_dir=\"./output/\")\n",
        "val_loader = build_detection_test_loader(cfg, \"dla_val\")\n",
        "print(inference_on_dataset(trainer.model, val_loader, evaluator))\n",
        "# another equivalent way to evaluate the model is to use `trainer.test`"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-yhFoxvurco"
      },
      "source": [
        "### Download fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HunigT5tuqty"
      },
      "source": [
        "files.download('fine_tunes_model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}