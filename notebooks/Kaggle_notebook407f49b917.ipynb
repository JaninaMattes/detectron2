{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !lsb_release -a \n!lspci | grep -i nvidia","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-30T11:35:41.996016Z","iopub.execute_input":"2021-06-30T11:35:41.996458Z","iopub.status.idle":"2021-06-30T11:36:03.552073Z","shell.execute_reply.started":"2021-06-30T11:35:41.996419Z","shell.execute_reply":"2021-06-30T11:36:03.550803Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved\n\"\"\"\nDetection Training Script.\n\nThis scripts reads a given config file and runs the training or evaluation.\nIt is an entry point that is made to train standard models in detectron2.\n\nIn order to let one script support training of many models,\nthis script contains logic that are specific to these built-in models and therefore\nmay not be suitable for your own project.\nFor example, your research project perhaps only needs a single \"evaluator\".\n\nTherefore, we recommend you to use detectron2 as an library and take\nthis file as an example of how to use the library.\nYou may want to write your own script with your datasets and other customizations.\n\"\"\"\n\nimport logging\nimport os\nimport datetime\nfrom collections import OrderedDict\nimport torch\n\nimport detectron2.utils.comm as comm\nfrom detectron2.checkpoint import DetectionCheckpointer\nfrom detectron2.config import get_cfg\nfrom detectron2.data import MetadataCatalog\nfrom detectron2.engine import DefaultFineTuner, default_argument_parser, default_setup, hooks, launch\nfrom detectron2.evaluation import (\n    CityscapesEvaluator,\n    COCOEvaluator,\n    COCOPanopticEvaluator,\n    DatasetEvaluators,\n    LVISEvaluator,\n    PascalVOCDetectionEvaluator,\n    SemSegEvaluator,\n    verify_results,\n)\nfrom detectron2.modeling import GeneralizedRCNNWithTTA\n\n\nfrom detectron2.data.datasets import register_coco_instances\nfrom detectron2.utils.logger import setup_logger\n\nlogger = logging.getLogger(\"detectron2\")\n\n\nclass FineTuner(DefaultFineTuner):\n    \"\"\"\n    We use the \"DefaultFineTuner\" which contains a number pre-defined logic for\n    standard training workflow. They may not work for you, especially if you\n    are working on a new research project. In that case you can use the cleaner\n    \"SimpleFineTuner\", or write your own training loop.\n    \"\"\"\n\n    @classmethod\n    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n        \"\"\"\n        Create evaluator(s) for a given dataset.\n        This uses the special metadata \"evaluator_type\" associated with each builtin dataset.\n        For your own dataset, you can simply create an evaluator manually in your\n        script and do not have to worry about the hacky if-else logic here.\n        \"\"\"\n        if output_folder is None:\n            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n        evaluator_list = []\n        evaluator_type = MetadataCatalog.get(dataset_name).evaluator_type\n        if evaluator_type in [\"sem_seg\", \"coco_panoptic_seg\"]:\n            evaluator_list.append(\n                SemSegEvaluator(\n                    dataset_name,\n                    distributed=False,\n                    num_classes=cfg.MODEL.SEM_SEG_HEAD.NUM_CLASSES,\n                    ignore_label=cfg.MODEL.SEM_SEG_HEAD.IGNORE_VALUE,\n                    output_dir=output_folder,\n                )\n            )\n        if evaluator_type in [\"coco\", \"coco_panoptic_seg\"]:\n            evaluator_list.append(COCOEvaluator(dataset_name, cfg, False, output_folder))\n        if len(evaluator_list) == 1:\n            return evaluator_list[0]\n        return DatasetEvaluators(evaluator_list)\n\n\ndef setup(args):\n    \"\"\"\n    Create configs and perform basic setups.\n    \"\"\"\n    cfg = get_cfg()\n    cfg.merge_from_file(args.config_file)\n    cfg.merge_from_list(args.opts)\n    cfg.freeze()\n    default_setup(cfg, args)\n    return cfg\n\n\ndef main(args):\n    cfg = setup(args)\n\n    if args.eval_only:\n        model = FineTuner.build_model(cfg)\n        DetectionCheckpointer(model, save_dir=cfg.OUTPUT_DIR).resume_or_load(\n            cfg.MODEL.WEIGHTS, resume=args.resume\n        )\n        res = FineTuner.test(cfg, model)\n        if comm.is_main_process():\n            verify_results(cfg, res)\n        if cfg.TEST.AUG.ENABLED:\n            res.update(FineTuner.test_with_TTA(cfg, model))\n        return res\n\n    \"\"\"\n    If you'd like to do anything fancier than the standard training logic,\n    consider writing your own training loop or subclassing the FineTuner.\n    \"\"\"\n    fineTuner = FineTuner(cfg)\n    fineTuner.resume_or_load(resume=args.resume)\n    if cfg.TEST.AUG.ENABLED:\n        fineTuner.register_hooks(\n            [hooks.EvalHook(0, lambda: fineTuner.test_with_TTA(cfg, fineTuner.model))]\n        )\n    return fineTuner.train()\n\n\nif __name__ == \"__main__\":\n    \"\"\"\n    Training with single GPU:\n    --config-file configs/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_1x.yaml \\\n\tSOLVER.IMS_PER_BATCH 2 SOLVER.BASE_LR 0.0025\n    \n    \"\"\"\n    args = default_argument_parser().parse_args()\n    output_dir = os.path.join('./output', datetime.datetime.now().strftime('%Y%m%dT%H%M'))\n    os.makedirs(output_dir, exist_ok=True)\n    logger = setup_logger(output=output_dir)\n    logger.info(\"Command Line Args:\", args)\n\n    register_coco_instances(\n        \"dla_train\",\n        {},\n        \"./datasets/siemens/train/train2021.json\",\n        \"./datasets/siemens/train/images\"\n    )\n\n    register_coco_instances(\n        \"dla_val\",\n        {},\n        \"./datasets/siemens/val/val2021.json\",\n        \"./datasets/siemens/val/images\"\n    )\n\n    metadata_train = MetadataCatalog.get(\"dla_train\")\n    metadata_val = MetadataCatalog.get(\"dla_val\")\n\n    cfg = get_cfg()\n    # mask rcnn resnet101\n    # cfg.merge_from_file(\"configs/DLA_mask_rcnn_R_101_FPN_3x.yaml\")\n    # mask rcnn resnext\n    cfg.merge_from_file(\"configs/DLA_mask_rcnn_X_101_32x8d_FPN_3x_Finetune.yaml\")\n\n    cfg.OUTPUT_DIR = output_dir\n\n    logger.info(cfg)\n\n    # serialize the training config\n    cfg_str = cfg.dump()\n    with open(os.path.join(cfg.OUTPUT_DIR, \"finetune_config.yaml\"), \"w\") as f:\n        f.write(cfg_str)\n    f.close()\n\n    fineTuner = FineTuner(cfg)\n    fineTuner.resume_or_load(resume=False)\n    fineTuner.train()\n","metadata":{},"execution_count":null,"outputs":[]}]}